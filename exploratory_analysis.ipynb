{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IO\n",
    "from pathlib import Path\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except ModuleNotFoundError:\n",
    "    import pickle\n",
    "\n",
    "# Utility Libraries\n",
    "import math\n",
    "from datetime import datetime\n",
    "import re\n",
    "import csv\n",
    "import itertools\n",
    "\n",
    "# Data Processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Predictive Analytics\n",
    "import statsmodels.stats.api as sms\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from pipeline import data, features, models, consts\n",
    "import shap\n",
    "\n",
    "# Viz\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "from matplotlib.dates import DateFormatter\n",
    "from matplotlib.cbook import boxplot_stats\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.transforms as mtrans\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'figure.autolayout': True})\n",
    "# plt.rcParams.update({'figure.facecolor': [1.0, 1.0, 1.0, 1.0]})\n",
    "\n",
    "# configure autoreloading of modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "datafile = Path(\"/mnt/c/Users/anbag/Box Sync/Research/UVA/Medication Adherance/MEMS dataset/final_merged_set_v6.csv\")\n",
    "# datafile = Path(\"/mnt/c/Users/ab5bt/Box Sync/Research/UVA/Medication Adherance/MEMS dataset/final_merged_set_v6.csv\")\n",
    "df = pd.read_csv(datafile, parse_dates=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning & Feature Engineering\n",
    "Thank you to Jason Brownlee\n",
    "https://machinelearningmastery.com/basic-data-cleaning-for-machine-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a Dataset class\n",
    "dataset = data.Dataset(df, id_col = 'PtID')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- Perform an initial cleaning of the dataset ----------\n",
    "dataset.clean(to_rename = {**consts.RENAMINGS['demographics'], \n",
    "                             **consts.RENAMINGS['medical']}, \n",
    "              to_drop=[col for col in dataset.df.columns if '_Name' in col] + \n",
    "                      ['MemsNum', 'Monitor'],\n",
    "              to_map = consts.CODEBOOK,\n",
    "              to_binarize = ['race_other'],\n",
    "              onehots_to_reverse = ['race_']\n",
    "             )\n",
    "\n",
    "''' Set dtypes on remaining columns\n",
    "For now, naively assume we only have numerics, datetimes, or objects\n",
    "'''\n",
    "dtypes_dict = {\n",
    "    'numeric': [col for col in dataset.df.columns if 'date' not in col.lower()],\n",
    "    'datetime': ['DateEnroll'],\n",
    "    'categorical': list(consts.CODEBOOK.keys()) + ['race']\n",
    "}\n",
    "\n",
    "dataset.set_dtypes(dtypes_dict)\n",
    "dataset.df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate static (non-temporal) features from measures such as validate instruments (e.g., FACTB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organize candidate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    " Organize the candidate features into useful categories for later reference\n",
    " A bit tedious, but helpful \n",
    "'''\n",
    "\n",
    "# Set our excluded features, before anything else\n",
    "excluded = ['percentMEMS8', 'total_days_8']  # Related to definition of adherence\n",
    "dataset.update_feature_categories({\n",
    "    'demographics': [v for v in consts.RENAMINGS['demographics'].values()\n",
    "                     if v in dataset.df.columns] + ['race'], #add the new, single race col\n",
    "    'study_behavior': [col for col in ['DateEnroll', 'Group', 'complete_4', \n",
    "                                       'complete_8', 'memsuse', 'deceased',\n",
    "                                       'day_miss_fromB', 'day_miss_from7'] \n",
    "                       if col in dataset.df.columns],\n",
    "    'medical': [v for v in consts.RENAMINGS['medical'].values() if v in dataset.df.columns] + \\\n",
    "               [col for col in ['early_late', 'diagtoenroll'] \n",
    "                if col in dataset.df.columns]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' This dataset has several repeated measures for validated instruments, \n",
    "such as the FACTB\n",
    "\n",
    "Columns for repeated measures for the same instrument share a suffix (e.g., '_FACTB')\n",
    "Use regex to populate the `scores` category subdictionary quickly, using these suffixes\n",
    "''' \n",
    "\n",
    "# TODO: Fix scores so that we only have one column per score\n",
    "# incorporate the shift halfway through the study (i.e. midpoint assessments)\n",
    "\n",
    "for k,v in consts.SCORES.items():\n",
    "    ''' Handle special case of BCPT before doing anything else '''\n",
    "    if k == 'BCPT':\n",
    "        dataset.df.drop(\n",
    "            list(dataset.df.filter(regex = '_BCPT\\d*YN$')), \n",
    "            axis = 1, \n",
    "            inplace = True\n",
    "        )\n",
    "        dataset.df.drop(\n",
    "            list(dataset.df.filter(regex = '_BCPT\\d*O$')), \n",
    "            axis = 1, \n",
    "            inplace = True\n",
    "        )\n",
    "    \n",
    "    '''Some measures weren't precalculated. Let's fix this \n",
    "    We'll only focus on time point A, since it doesn't make sense to make predictions using\n",
    "    future scores!\n",
    "    ''' \n",
    "    if v['precalculated'] == False:\n",
    "        \n",
    "        ''' For the baseline time point, get the aggregate score and add it to the dataset\n",
    "        as a new column'''\n",
    "        prefix = 'A'\n",
    "        score_cols = list(\n",
    "            dataset.df.filter(regex='^' + prefix + v['suffix'] + '\\d*').columns\n",
    "        )\n",
    "        \n",
    "        dataset.df[prefix + v['suffix']] = dataset.df[score_cols].sum(axis=1)\n",
    "    '''We'll include this new column as a feature shortly'''\n",
    "   \n",
    "    dataset.update_feature_categories({\n",
    "        'scores': [prefix + v['suffix']]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Create a catch-all category of remaining features, to ensure we got everything '''\n",
    "dataset.update_feature_categories({\n",
    "    'other': [col for col in dataset.df.columns \n",
    "              if col not in list(itertools.chain(*dataset.feature_categories.values())) # exclude anything already in the list\n",
    "              and not any(prefix in col for prefix in ['A_', 'B_', 'C_']) # exclude individual score cols\n",
    "              and 'date' not in col \n",
    "              and col not in dataset.id_col\n",
    "              and col not in excluded\n",
    "             ]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.feature_categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Create new columns for several demographic and medical variables\n",
    "Be sure we update the feature categories dictionary '''\n",
    "\n",
    "demog_drug_cols = [col for col in dataset.df.columns if 'A_DEMO13DRUG' in col]\n",
    "newcol = 'DEMOG_numdrugs'\n",
    "dataset.df[newcol] = dataset.df[demog_drug_cols].count(axis=1)\n",
    "dataset.update_feature_categories({'demographics': [newcol]})\n",
    "\n",
    "post_exam_cols = [col for col in dataset.df.columns if 'C_MR5_date' in col]\n",
    "dataset.df[post_exam_cols] = dataset.df[post_exam_cols].apply(\n",
    "    lambda x: pd.to_datetime(x, errors='coerce')\n",
    ")\n",
    "newcol = 'C_numexams'\n",
    "dataset.df[newcol] = dataset.df[post_exam_cols].count(axis=1)\n",
    "dataset.update_feature_categories({'medical': [newcol]})\n",
    "\n",
    "''' Thank you @benvc!\n",
    "https://stackoverflow.com/questions/54367491/calculate-average-of-days-between-a-list-of-dates\n",
    "'''\n",
    "\n",
    "# TODO: Dates aren't necessarily in order. Ask Kristi if this is a data entry issue or \n",
    "# An ordering issue?\n",
    "newcol = 'mean_days_betw_exams'\n",
    "dataset.df[newcol] = dataset.df[post_exam_cols].apply(\n",
    "    lambda x: features.mean_days_between_dates(x),\n",
    "    axis=1\n",
    ")\n",
    "dataset.update_feature_categories({'medical': [newcol]})\n",
    "\n",
    "# Ensure everything looks good\n",
    "print(dataset.df['DEMOG_numdrugs'].head())\n",
    "print(dataset.df['C_numexams'].head())\n",
    "print(dataset.df['mean_days_betw_exams'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Impute numerics and categoricals (encoded as nominal numerics) ----\n",
    "numeric_cols = set(list(dataset.df.select_dtypes('number').columns))-set([dataset.id_col])\n",
    "\n",
    "# Let's be efficient and only impute our candidate features\n",
    "feature_cols = set(list(itertools.chain(\n",
    "                     *[v for k,v in dataset.feature_categories.items()])\n",
    "                   )\n",
    "                  )\n",
    "numeric_cols = list(numeric_cols.intersection(feature_cols))\n",
    "\n",
    "# Grab our categoricals as well\n",
    "categorical_cols = list(consts.CODEBOOK.keys()) + ['race']\n",
    "\n",
    "# Pre-imputation visual inspection\n",
    "dataset.df[categorical_cols].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the imputation\n",
    "dataset.df = features.impute(df=dataset.df, id_col=dataset.id_col, \n",
    "                             numerics=numeric_cols, categoricals=categorical_cols)\n",
    "\n",
    "# Imputation sanity check\n",
    "dataset.df[feature_cols].isnull().values.any()\n",
    "\n",
    "# Post-imputation visual inspection\n",
    "dataset.df[categorical_cols].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual inspection for multicollinearity\n",
    "sns.set(rc={'figure.figsize':(20, 20)})\n",
    "sns.heatmap(dataset.df[dataset.feature_categories['scores']].corr(), annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Remove highly-correlated scores as well as the FACT-G breast cancer subscale score \n",
    "(too correlated with other subscales - already marked that we shouldn't include it, \n",
    "in the consts.SCORES dictionary)'''\n",
    "\n",
    "new_scores = set(dataset.feature_categories['scores']) -\\\n",
    "                set(['A_BACS', 'A_MASES', 'A_BCPT', 'A_BC', 'A_CASE', 'A_FACITSP', 'A_MDASI'])\n",
    "dataset.update_feature_categories({'scores': list(new_scores)}, replace=True)\n",
    "\n",
    "# Re-inspect\n",
    "sns.set(rc={'figure.figsize':(20, 20)})\n",
    "sns.heatmap(dataset.df[dataset.feature_categories['scores']].corr(), annot=True)\n",
    "plt.show()\n",
    "\n",
    "''' Looks good, with one caveat: \n",
    "    We know the FACT-B, FACT-G, and FACT-G subscale scores are highly correlated (obvious)\n",
    "    We'll generate featuresets for each of these score types - one that uses only subscale scores, \n",
    "    one that uses only the full FACT-G score, and one that uses the full FACT-B score\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create featuresets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_featuresets = list()\n",
    "categories = list(dataset.feature_categories.keys())\n",
    "n_categories = len(categories)\n",
    "fact_subscales = ['A' + v['suffix'] for k,v in consts.SCORES.items() if v['subscale_include'] == True]\n",
    "drop_pairs = [\n",
    "    ('FACTB Subset', ['A_FACTG'] + fact_subscales), # FACT-B only\n",
    "    ('FACTB Subscales Subset', ['A_FACTB', 'A_FACTG']), # FACT-B subscales only\n",
    "    ('FACTG Subset', ['A_FACTB'] + fact_subscales) # FACT-G only\n",
    "]\n",
    "\n",
    "print(fact_subscales)\n",
    "\n",
    "import itertools\n",
    "for i in range(1, n_categories + 1):\n",
    "    for t in list(itertools.combinations(categories,i)):\n",
    "        subcategories = list(t)\n",
    "        name = ' + '.join(subcategories)\n",
    "        \n",
    "        '''For each featureset, create three further subsets related to FACT scores '''\n",
    "        df = dataset.build_df_from_feature_categories(subcategories)\n",
    "        \n",
    "        if 'scores' in subcategories:\n",
    "            \n",
    "            # If this is a featureset that includes scores, add the FACT-related subsets\n",
    "            for (subset_name, drop_cols) in drop_pairs:\n",
    "                df2 = df.drop(columns=drop_cols) # Returns a copy\n",
    "                static_featuresets.append(features.Featureset(df=df2, name=name + ' - ' + subset_name, \n",
    "                                                              id_col = dataset.id_col))\n",
    "        else:\n",
    "            static_featuresets.append(features.Featureset(df=df, name=name, id_col = dataset.id_col))\n",
    "        \n",
    "static_featuresets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic (Temporal) Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract temporal features by converting main dataset's df from wide-form to long-form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "# Get a list of all date columns\n",
    "date_cols = list(dataset.df.filter(regex='date\\d{3}$').columns)\n",
    "\n",
    "i = 0\n",
    "for col in date_cols:\n",
    "\n",
    "    # Find all the time cols for that date col\n",
    "    time_cols = list(dataset.df.filter(\n",
    "        regex='MEMS_{date_col}_time\\d{{1}}$'.format(date_col=col)).columns)  \n",
    "\n",
    "    ''' Perform a melt so we get MEMS events stratified by patient\n",
    "        Be sure to include the \"within range\" column as one of the id_vars''' \n",
    "    additional_cols = [\n",
    "        {\n",
    "            'original': 'MEMS_' + col + '_numtimes',\n",
    "            'new': 'num_times_used_today'\n",
    "        }\n",
    "    ]\n",
    "    if i > 0: # The first date won't have an interval or withinrange\n",
    "        additional_cols.append(\n",
    "            {\n",
    "                'original': 'MEMS_' + col + '_interval',\n",
    "                'new': 'interval'\n",
    "            }\n",
    "        )\n",
    "        additional_cols.append(\n",
    "            {\n",
    "                'original': 'MEMS_' + col + '_withinrange',\n",
    "                'new': 'withinrange'\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    all_id_col = [dataset.id_col, 'DateEnroll', col] + [x['original'] for x in additional_cols]\n",
    "    \n",
    "    res = dataset.df[all_id_col + time_cols].melt(id_vars = all_id_col)\n",
    "    \n",
    "    # Tidy up the resulting dataframe\n",
    "    res.rename(columns={col: 'date', 'value': 'time', 'variable': 'MEMS_day'}, \n",
    "               inplace=True)\n",
    "\n",
    "    res['MEMS_day'] =  res['MEMS_day'].apply(lambda x: int(re.sub(r'_time\\d*$', '', x.split('MEMS_date')[1])))\n",
    "    \n",
    "    res.rename(columns={x['original']:x['new'] for x in additional_cols},\n",
    "               inplace=True)\n",
    "\n",
    "#     res.drop(columns=['variable'], inplace=True)\n",
    "    \n",
    "    rows.append(res) # TODO - double check this...getting a weird warning about index alignment\n",
    "    i += 1\n",
    "\n",
    "df = pd.concat(rows, axis=0)\n",
    "\n",
    "# Create combined datetime column\n",
    "df['datetime'] = df.apply(\n",
    "    lambda x: features.get_datetime_col(x), axis=1\n",
    ")\n",
    "df['datetime'] = pd.to_datetime(df['datetime'], errors='coerce')\n",
    "\n",
    "# Fix dtypes\n",
    "df[['withinrange', 'num_times_used_today']] = df[['withinrange', 'num_times_used_today']].fillna(0).astype(int)\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "df['interval'] = pd.to_timedelta(df['interval']) # Handle NaT intervals for first day?\n",
    "\n",
    "'''Drop rows with an empty date column.\n",
    "  Do NOT drop empty time columns - may have dates where it is recorded that the patient\n",
    "  did not use the cap. So, would have a date but no time. Need this info to calculate\n",
    "  additional stats later\n",
    "''' \n",
    "df.dropna(subset=['date'], inplace=True)\n",
    "\n",
    "# Drop duplicates - these must have been introduced with the melt and with how Kristi's original data was structured\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Remove observations that occurred before a subject's enrollment date\n",
    "df = df.loc[df['DateEnroll'] < df['date']]\n",
    "\n",
    "# Restrict to 210 MEMS days (not necessarily study days), per Kristi's documentation\n",
    "df = df[df['MEMS_day'] <= 210] \n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check - Validate that we calculated days of adherence correctly\n",
    "df2 = df.groupby([dataset.id_col, 'MEMS_day'])['withinrange'].max().reset_index()\n",
    "df2 = df2.groupby(dataset.id_col)['withinrange'].sum().reset_index()\n",
    "df2 = df2.merge(dataset.df[[dataset.id_col, 'total_days_8']])\n",
    "df2.head(10)\n",
    "# Check!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add binary indicator of any usage (not just number of times used) on a given day\n",
    "df['used_today'] = df['num_times_used_today'].apply(\n",
    "    lambda x: 1 if x > 0 else 0\n",
    ")\n",
    "\n",
    "'''Generate epochs of interest (time of day, weekday, day/month of study, etc)\n",
    "   'time_of_day' category gets automatically encoded as a Categorical\n",
    "''' \n",
    "time_of_day_props = {\n",
    "    'bins': [-1, 6, 12, 18, 24],\n",
    "    'labels': ['early_morning', 'morning', 'afternoon', 'evening']\n",
    "}\n",
    "df = features.get_epochs(df, 'DateEnroll', 'PtID',\n",
    "                         time_of_day_props['bins'], \n",
    "                         time_of_day_props['labels'])\n",
    "df.head()\n",
    "\n",
    "# TODO - figure out a way to use the times of day? Not currently being used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude first month (ramp-up period during which time users were getting used to the MEMS caps)\n",
    "df = df[df['study_month'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_featuresets = list()\n",
    "'''Group by our desired epoch and add standard metrics such as mean, std\n",
    "'''\n",
    "\n",
    "# TODO - add ability to calculate adherence metrics by month, extend epochs to include months\n",
    "# Will need a way to find days in a given month...\n",
    "\n",
    "for epoch in ['study_week']:\n",
    "    groupby_cols = [dataset.id_col, epoch]\n",
    "    temporal_feats = features.calc_standard_temporal_metrics(df, groupby_cols, 'datetime')\n",
    "    \n",
    "    # Calculate avg and standard deviation of number of times used\n",
    "    df2 = df.groupby(groupby_cols + ['study_day'])['num_times_used_today'].max().reset_index()\n",
    "    df2 = df.groupby(groupby_cols)['num_times_used_today'].agg({\n",
    "        'num_daily_events_mean': lambda x: x.sum() / consts.DAYS_IN_WEEK\n",
    "    }).reset_index()\n",
    "    temporal_feats = temporal_feats.merge(df2, on=groupby_cols)\n",
    "    \n",
    "    # Get most common time of day of event occurence\n",
    "    df2 = df.groupby(groupby_cols)['time_of_day'].agg({\n",
    "        'event_time_of_day_mode': pd.Series.mode\n",
    "    }).reset_index().drop(columns=['level_2'])\n",
    "    temporal_feats = temporal_feats.merge(df2, on=groupby_cols)\n",
    "    print(temporal_feats)\n",
    "    \n",
    "    # Calculate adherence rate (percentage of time in range)\n",
    "    df2 = df.groupby(groupby_cols + ['study_day'])['withinrange'].max().reset_index() # Max will be 1 or 0\n",
    "    df2 = df2.groupby(groupby_cols)['withinrange'].agg({\n",
    "        'adherence_rate': lambda x: x.sum() / consts.DAYS_IN_WEEK\n",
    "    }).reset_index()\n",
    "    temporal_feats = temporal_feats.merge(df2, on=groupby_cols)\n",
    "    \n",
    "    \n",
    "    # Impute and add to temporal featuresets dictionary\n",
    "    numeric_cols = list(set(list(temporal_feats.select_dtypes('number').columns)) -\\\n",
    "                set([dataset.id_col]))\n",
    "    \n",
    "    temporal_feats = features.common.impute(temporal_feats, dataset.id_col, numerics=numeric_cols)\n",
    "    temporal_featuresets.append(features.Featureset(df=temporal_feats,\n",
    "                                                    name=epoch, #Intentional for now - using epoch as name\n",
    "                                                    id_col=dataset.id_col,\n",
    "                                                    epoch=epoch\n",
    "                                                   )\n",
    "                               )\n",
    "temporal_featuresets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation sanity check\n",
    "for fs in temporal_featuresets:\n",
    "    print(fs.df.isnull().values.any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(10,10)})\n",
    "sns.heatmap(temporal_featuresets[0].df.corr(), annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fs in temporal_featuresets:\n",
    "    fs.df.drop(columns=['event_time_min', 'event_time_max'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(10,10)})\n",
    "sns.heatmap(temporal_featuresets[0].df.corr(), annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine static and dynamic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_static_featuresets = []\n",
    "\n",
    "''' For now, let's hand-select\n",
    "Later we will run all possible combos...if it doesn't take for-freakin ever'''\n",
    "\n",
    "for subset in ['FACTB Subset', 'FACTG Subset', 'FACTB Subscales Subset']:\n",
    "    selected_static_featuresets.append(\n",
    "        next(\n",
    "            (fs for fs in static_featuresets \n",
    "             if fs.name == 'demographics + study_behavior + medical + scores + other - ' + subset), \n",
    "            None\n",
    "        )\n",
    "    )\n",
    "n_static_featuresets = len(selected_static_featuresets)\n",
    "print(n_static_featuresets)\n",
    "selected_static_featuresets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_static_featuresets[3].df['total_days_8']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run prediction tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune lags and featureset first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = []\r\n",
    "target_col = 'adherent'\r\n",
    "\r\n",
    "# Test the performance for a range of lags (number of previous inputs)\r\n",
    "'''TODO - ask Laura and Mehdi about best way to tune number of lags \r\n",
    "(using temporal data only? Temporal and a randomly-selected subset of static data?)\r\n",
    "'''\r\n",
    "\r\n",
    "for temporal_feats in temporal_featuresets:\r\n",
    "    \r\n",
    "    # Convert adherence_rate into a binary indicator of adherence\r\n",
    "    temporal_feats.df[target_col] = temporal_feats.df['adherence_rate'].apply(\r\n",
    "        lambda x: 1 if x > consts.ADHERENCE_THRESHOLD else 0\r\n",
    "    )\r\n",
    "    # Drop the original column\r\n",
    "    temporal_feats.df.drop(columns=['adherence_rate'], inplace=True)\r\n",
    "\r\n",
    "    # Set the target col\r\n",
    "    temporal_feats.target_col = target_col\r\n",
    "    \r\n",
    "    for n_lags in range(2, 16):\r\n",
    "        print('For ' + str(n_lags) + ' lags...')\r\n",
    "        results = []\r\n",
    "\r\n",
    "        # Get a lagged featureset\r\n",
    "        all_feats = temporal_feats.get_lagged_featureset(n_lags=n_lags)\r\n",
    "\r\n",
    "        '''Perform final encoding, scaling, etc\r\n",
    "        Be sure we pass in all known categoricals (they're in numeric form - just need to be one-hot encoded)'''\r\n",
    "        all_feats.prep_for_modeling()\r\n",
    "        \r\n",
    "        # Do 10 runs per lag\r\n",
    "        print('Running prediction 10 times...')\r\n",
    "        for j in range(0,10):\r\n",
    "\r\n",
    "            # Do our actual predictions\r\n",
    "            # Use defaults in this go-round, rather than gridsearch\r\n",
    "            res = models.predict(all_feats, n_lags, classifiers=['RF'], tune=False, importance=False)\r\n",
    "            results.append(res)\r\n",
    "\r\n",
    "        lag_results = pd.concat(results, axis=0)\r\n",
    "        lag_results.to_csv('results/prelim_pred_results_' + str(n_lags) + '_lags.csv',index=False)\r\n",
    "        all_results.append(lag_results)\r\n",
    "\r\n",
    "results = pd.concat(all_results, axis=0)\r\n",
    "results.to_csv('results/prelim_pred_results_all_lags.csv',index=False)\r\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv('results/prelim_pred_results_all_lags.csv')\r\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x='n_lags',y='test_accuracy', hue='featureset', data=results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'adherent'\r\n",
    "n_lags = 4\r\n",
    "all_results = []                                  \r\n",
    "\r\n",
    "# TODO: Change so that we feed only the X most predictive features (according to SHAP scores)\r\n",
    "# from the random forest into the SVM\r\n",
    "# Saw this approach in a diff paper...just need to remember where\r\n",
    "# Will likely help performance\r\n",
    "\r\n",
    "# ----- Run LR and tree-based classifiers using 4 lags only --- \r\n",
    "\r\n",
    "for temporal_feats in temporal_featuresets:\r\n",
    "    for i in range(-1, n_static_featuresets):\r\n",
    "\r\n",
    "        # Get a lagged featureset\r\n",
    "        all_feats = temporal_feats.get_lagged_featureset(n_lags=4)\r\n",
    "\r\n",
    "        # For the first index (i== -1), get results for only the temporal feats on their own\r\n",
    "        if i >= 0:\r\n",
    "\r\n",
    "            # Otherwise, create a combined set with one of the static featuresets\r\n",
    "            all_feats = all_feats.create_combined_featureset(fs=selected_static_featuresets[i])\r\n",
    "\r\n",
    "        '''Perform final encoding, scaling, etc\r\n",
    "        Be sure we pass in all known categoricals (they're in numeric form - just need to be one-hot encoded)'''\r\n",
    "        all_feats.prep_for_modeling()\r\n",
    "\r\n",
    "        print('For featureset \"' + all_feats.name + '\"...')\r\n",
    "\r\n",
    "        # Do our actual predictions WITHOUT tuning first, to get a baseline\r\n",
    "        res = models.predict(all_feats, n_lags, classifiers=['LogisticR', 'RF', 'XGB'], tune=False)\r\n",
    "        print(res)\r\n",
    "        all_results.append(res)           \r\n",
    "\r\n",
    "        # Do our actual predictions WITH tuning\r\n",
    "        res = models.predict(all_feats, n_lags, classifiers=['LogisticR', 'RF', 'XGB'], tune=True)\r\n",
    "        print(res)\r\n",
    "        all_results.append(res)                                                  \r\n",
    "\r\n",
    "results = pd.concat(all_results, axis=0)\r\n",
    "results.to_csv('results/final_pred_results_all.csv', index=False)\r\n",
    "results         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_scores = pickle.load(open('feature_importance/shap_RF_' + str(n_lags) + '_lags.ob', 'rb'))\r\n",
    "X_test = pd.read_pickle('feature_importance/X_test_RF_' + str(n_lags) + '_lags.ob')\r\n",
    "X_test.columns = [x.replace('_', ' ').capitalize() if 'A_' not in x else x.replace('A_', '') for x in X_test.columns]\r\n",
    "shap.summary_plot(shap_scores[1], X_test, show=False)\r\n",
    "fig = plt.gcf()\r\n",
    "fig.set_size_inches(12.5, 8.5)\r\n",
    "plt.savefig('feature_importance/RF.png')\r\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bcpn_mems",
   "language": "python",
   "name": "bcpn_mems"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
